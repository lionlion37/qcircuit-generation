general:
  output_path: ./models/trained/
  model_name: cloob_rn50x4_model  # TODO: this is also present below under training
  experiment_name: cloob_rn50x4_model_training  # TODO: this is also present below under training
  dataset: ./datasets/paper_qiskit/ # ./datasets/paper_qiskit
  njobs: 16
  device: auto
  resume: false
  verbose: true

model:
  type: QC_Cond_UNet
  save_type: pt

  params:
    model_features: [128, 128, 256]
    clr_dim: 8
    num_clrs: 9
    t_emb_size: 256
    cond_emb_size: 640
    num_heads: [8, 8, 2]
    num_res_blocks: [2, 2, 2]
    transformer_depths: [1, 1, 1]

training:
  learning_rate: 3e-4
  optimizer: Adam
  loss: MSELoss
  num_epochs: 75
  batch_size: 256 
  enable_guidance_train: true
  guidance_train_p: 0.1
  cached_text_enc: true
  output_path: ./models/trained/
  model_name: cloob_rn50x4_model
  experiment_name: cloob_rn50x4_model_training
  ckpt_path: ./cp_saves/
  ckpt_interval: 3
  wandb:
    enable: true
    project: qcircuit-generation
    run_name: cloob_rn50x4_model_training

text_encoder:
  type: CachedFrozenOpenCLIPEmbedder
  params:
    arch: RN50x4
    version: null #./models/encoders/RN50.pt # openai
    max_length: 77
    freeze: true
    layer: penultimate
    enable_cache_token_limit: true
    local_weights_path: "./models/encoders/clip_rn50x4_yfcc_epoch_28.pt"

scheduler:
  type: DDIMScheduler
  params:
    num_train_timesteps: 1000
    beta_start: 0.0001
    beta_end: 0.02
    beta_schedule: cos_alpha
    input_perturbation: 0.1
    prediction_type: epsilon
    eta: 1
