{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af5d14b1-7de6-447f-ba74-214d35cbcbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import ast\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "import hydra\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Ensure local src/ is importable\n",
    "sys.path.insert(0, str(Path(os.getcwd()).parent / \"src\"))\n",
    "\n",
    "from my_genQC.inference.eval_metrics import UnitaryFrobeniusNorm, UnitaryInfidelityNorm\n",
    "from my_genQC.inference.evaluation_helper import get_unitaries, get_srvs\n",
    "from my_genQC.inference.sampling import generate_compilation_tensors, generate_tensors, decode_tensors_to_backend\n",
    "from my_genQC.pipeline.diffusion_pipeline import DiffusionPipeline\n",
    "from my_genQC.platform.simulation import Simulator, CircuitBackendType\n",
    "from my_genQC.platform.tokenizer.circuits_tokenizer import CircuitTokenizer\n",
    "from my_genQC.utils.misc_utils import infer_torch_device, get_entanglement_bins\n",
    "from my_genQC.dataset import circuits_dataset\n",
    "from my_genQC.models.config_model import ConfigModel\n",
    "from my_genQC.utils.config_loader import load_config, store_tensor, load_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16a115b6-58b5-4cef-9f7b-102b1f87ba12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Loading tensor from `../datasets/paper_quditkit/srv_8q_dataset/dataset/ds_x.safetensors` onto device: cuda.\n",
      "[INFO]: Loading tensor from `../datasets/paper_quditkit/srv_8q_dataset/dataset/ds_y.safetensors` onto device: cuda.\n",
      "[INFO]: Instantiated config_dataset from given config on cuda.\n"
     ]
    }
   ],
   "source": [
    "def load_dataset(dataset_path: Path, device: torch.device):\n",
    "    config_path = os.path.join(dataset_path, \"config.yaml\")\n",
    "\n",
    "    if not os.path.exists(config_path):\n",
    "        raise FileNotFoundError(f\"Config file not found at {config_path}\")\n",
    "\n",
    "    cfg_data = load_config(config_path)\n",
    "    target = cfg_data.get(\"target\", \"\")\n",
    "    if target.endswith(\"MixedCircuitsConfigDataset\"):\n",
    "        dataset_cls = circuits_dataset.MixedCircuitsConfigDataset\n",
    "    else:\n",
    "        dataset_cls = circuits_dataset.CircuitsConfigDataset\n",
    "\n",
    "    dataset = dataset_cls.from_config_file(\n",
    "        config_path=config_path,\n",
    "        device=device,\n",
    "        save_path=os.path.join(dataset_path, \"dataset\", \"ds\")\n",
    "    )\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "ds = load_dataset(\"../datasets/paper_quditkit/srv_8q_dataset\", device=\"cuda\")\n",
    "samples = ds.x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dd31814-5cbf-4ff1-87f1-900881a689d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Loading tensor from `../scripts/inference/8q_599936_samples.pt` onto device: cuda.\n"
     ]
    }
   ],
   "source": [
    "tensor_out = load_tensor(\"../scripts/inference/8q_599936_samples.pt\", device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b315a7b-ce15-487b-8f79-4b5f5fe553c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx_shuffled = torch.randperm(len(tensor_out))\n",
    "# tensor_out_shuffled = tensor_out[idx_shuffled]\n",
    "# tensor_out = tensor_out[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cca4ae26-85ec-4065-9cf4-5a17282b8f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING]: The value 0 is reserved for background tokens, i.e. qubit time position which are not effected by gates.\n",
      "[WARNING]: Automatically incrementing all vocabulary values by one ...\n"
     ]
    }
   ],
   "source": [
    "vocabulary = {gate: idx for idx, gate in enumerate(ds.gate_pool)}\n",
    "tokenizer = CircuitTokenizer(vocabulary)\n",
    "simulator = Simulator(CircuitBackendType.QISKIT) #.QUDITKIT)\n",
    "pqdm(loop_set, f, n_jobs=n_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb435e20-0451-48e6-8336-526353791238",
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_genQC.utils.async_fn import run_parallel_jobs\n",
    "from my_genQC.platform.simulation import Simulator \n",
    "from my_genQC.platform.tokenizer.base_tokenizer import BaseTokenizer\n",
    "from my_genQC.pipeline.pipeline import Pipeline\n",
    "\n",
    "from typing import Optional, Sequence\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pqdm.threads import pqdm\n",
    "\n",
    "def exists(val): \n",
    "    return val is not None\n",
    "\n",
    "def _chunk_iterable(it, size: int):\n",
    "    \"\"\"Yield fixed-size chunks from any iterable without materializing the whole thing.\"\"\"\n",
    "    chunk = []\n",
    "    for item in it:\n",
    "        chunk.append(item)\n",
    "        if len(chunk) == size:\n",
    "            yield chunk\n",
    "            chunk = []\n",
    "    if chunk:\n",
    "        yield chunk\n",
    "\n",
    "\n",
    "def run_parallel_jobs(f: callable,\n",
    "                      loop_set,\n",
    "                      n_jobs: int = 1,\n",
    "                      prefer: str = \"processes\",\n",
    "                      batch_size: int | None = None):\n",
    "    \"\"\"\n",
    "    Run a function in parallel over an iterable.\n",
    "\n",
    "    - prefer=\"processes\" avoids the GIL for Python-heavy work (default).\n",
    "    - batch_size groups items to amortize scheduling/pickling overhead.\n",
    "    \"\"\"\n",
    "    # fast path\n",
    "    if n_jobs == 1:\n",
    "        return [f(x) for x in loop_set]\n",
    "\n",
    "    if batch_size:\n",
    "        def _run_batch(batch):\n",
    "            return [f(x) for x in batch]\n",
    "\n",
    "        batches = _chunk_iterable(loop_set, batch_size)\n",
    "        res_batches = Parallel(n_jobs=n_jobs,\n",
    "                               prefer=prefer,\n",
    "                               batch_size=\"auto\")(delayed(_run_batch)(b) for b in batches)\n",
    "        # flatten\n",
    "        return [item for batch in res_batches for item in batch]\n",
    "\n",
    "    return Parallel(n_jobs=n_jobs,\n",
    "                    prefer=prefer,\n",
    "                    batch_size=\"auto\")(delayed(f)(x) for x in loop_set)\n",
    "\n",
    "\n",
    "def decode_tensors_to_backend(simulator: Simulator, \n",
    "                              tokenizer: BaseTokenizer, \n",
    "                              tensors: torch.Tensor, \n",
    "                              params: Optional[torch.Tensor] = None, \n",
    "                              silent: bool = True,\n",
    "                              n_jobs: int = 1,\n",
    "                              filter_errs: bool = True,\n",
    "                              return_tensors: bool = False,\n",
    "                    ) -> tuple[Sequence[any], int] | tuple[Sequence[any], int, torch.Tensor]:\n",
    "    tensors = tensors.cpu()\n",
    "\n",
    "    if exists(params):\n",
    "        params  = params.cpu()\n",
    "        iter_pack = zip(tensors, params)\n",
    "        _decode   = lambda x, p: tokenizer.decode(x, p)\n",
    "        \n",
    "    else:\n",
    "        iter_pack = zip(tensors, )\n",
    "        _decode   = lambda x: tokenizer.decode(x)\n",
    "    \n",
    "    def _f(iter_vars):\n",
    "        try:\n",
    "            instructions = _decode(*iter_vars)\n",
    "            backend_obj  = simulator.backend.genqc_to_backend(instructions, place_barriers=False)\n",
    "            return backend_obj\n",
    "        except Exception as err:\n",
    "            if silent: return None\n",
    "            raise err\n",
    "        \n",
    "    pot_qcs = run_parallel_jobs(_f, iter_pack, n_jobs)\n",
    "\n",
    "    if filter_errs:\n",
    "        backend_obj_list = [pot_qc for pot_qc in pot_qcs if exists(pot_qc)]\n",
    "        err_cnt          = sum(1 for pot_qc in pot_qcs if not_exists(pot_qc))\n",
    "        assert len(backend_obj_list) + err_cnt == len(pot_qcs)\n",
    "\n",
    "        if return_tensors:\n",
    "            tensors = tensors[torch.tensor([exists(pot_qc) for pot_qc in pot_qcs])]\n",
    "        \n",
    "    else:\n",
    "        backend_obj_list = pot_qcs\n",
    "        err_cnt = None\n",
    "\n",
    "    if return_tensors:\n",
    "        return backend_obj_list, err_cnt, tensors\n",
    "    return backend_obj_list, err_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4831eaba-e16d-4346-b1cb-23976e79d73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_circuits, _ = decode_tensors_to_backend(\n",
    "    simulator=simulator,\n",
    "    tokenizer=tokenizer,\n",
    "    tensors=tensor_out,\n",
    "    silent=True,\n",
    "    params=None,\n",
    "    n_jobs=24,\n",
    "    filter_errs=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "91831e14-0941-4f52-a8fd-4fb1d70afd87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<qiskit.circuit.quantumcircuit.QuantumCircuit at 0x78593c65b9d0>,\n",
       " <qiskit.circuit.quantumcircuit.QuantumCircuit at 0x7859de3ac990>,\n",
       " <qiskit.circuit.quantumcircuit.QuantumCircuit at 0x785937bd8590>,\n",
       " <qiskit.circuit.quantumcircuit.QuantumCircuit at 0x78593c63e890>,\n",
       " <qiskit.circuit.quantumcircuit.QuantumCircuit at 0x785937fb9550>,\n",
       " <qiskit.circuit.quantumcircuit.QuantumCircuit at 0x785937bae350>,\n",
       " None,\n",
       " <qiskit.circuit.quantumcircuit.QuantumCircuit at 0x785937b7e690>,\n",
       " <qiskit.circuit.quantumcircuit.QuantumCircuit at 0x78593c619610>,\n",
       " <qiskit.circuit.quantumcircuit.QuantumCircuit at 0x785937b70c50>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_circuits[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c287afb-66cd-4589-abf9-a7ffc5d976f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== genQC Evaluation ====\n",
      "Samples requested: 599936\n",
      "Decoded circuits : 926\n",
      "Decode failures  : 74\n"
     ]
    }
   ],
   "source": [
    "valid = [(idx, qc) for idx, qc in enumerate(decoded_circuits) if qc is not None]\n",
    "valid_indices = [idx for idx, _ in valid]\n",
    "backend_circuits = [qc for _, qc in valid]\n",
    "err_cnt = len(decoded_circuits) - len(backend_circuits)\n",
    "\n",
    "print(\"==== genQC Evaluation ====\")\n",
    "print(f\"Samples requested: {samples}\")\n",
    "print(f\"Decoded circuits : {len(backend_circuits)}\")\n",
    "print(f\"Decode failures  : {err_cnt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "58fc8306-ae6c-438f-89cd-9a408c8e63ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_size = ds.x.shape[1]\n",
    "max_gates = ds.x.shape[2]\n",
    "num_qubits = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d0115b3d-9cd6-4452-b1bf-9feca74efd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_srv_targets(labels: np.ndarray) -> torch.Tensor:\n",
    "    \"\"\"Extract SRV vectors from stored prompt strings.\"\"\"\n",
    "    srv_list = []\n",
    "    for label in labels:\n",
    "        text = str(label)\n",
    "        start = text.find(\"[\")\n",
    "        end = text.find(\"]\", start)\n",
    "        if start == -1 or end == -1:\n",
    "            raise ValueError(f\"Could not parse SRV from label: {text}\")\n",
    "        srv = ast.literal_eval(text[start:end+1])\n",
    "        srv_list.append(srv)\n",
    "    return torch.tensor(srv_list, dtype=torch.long)\n",
    "\n",
    "\n",
    "def entanglement_histogram(srvs: torch.Tensor, num_qubits: int) -> tuple[list[float], list[str], float]:\n",
    "    \"\"\"Return histogram over entanglement bins defined in genQC.\"\"\"\n",
    "    if srvs.numel() == 0:\n",
    "        return [], [], 0.0\n",
    "\n",
    "    bins, labels = get_entanglement_bins(num_qubits)\n",
    "    mapping = {}\n",
    "    for idx, bucket in enumerate(bins):\n",
    "        for vector in bucket:\n",
    "            mapping[tuple(vector)] = idx\n",
    "\n",
    "    counts = Counter(mapping.get(tuple(vec.tolist()), -1) for vec in srvs)\n",
    "    total = srvs.shape[0]\n",
    "    hist = [counts.get(i, 0) / total for i in range(len(labels))]\n",
    "    other_ratio = counts.get(-1, 0) / total\n",
    "    return hist, labels, other_ratio\n",
    "\n",
    "\n",
    "def get_srvs(simulator: Simulator, backend_obj_list: Sequence, n_jobs: int = 1, **kwargs): \n",
    "    \"\"\"Returns SRVs of a given list of backen objects `backend_obj_list`.\"\"\"\n",
    "    def _f(backend_obj):\n",
    "        return simulator.backend.schmidt_rank_vector(backend_obj, **kwargs)\n",
    "        \n",
    "    return run_parallel_jobs(_f, backend_obj_list, n_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "75d2e174-3447-4ea1-b0ee-4ac16a6aa418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e2195cd3c5d4832981583f9514527e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QUEUEING TASKS | :   0%|          | 0/926 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec2e2b9456b548efb82cb45461c3f954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PROCESSING TASKS | :   0%|          | 0/926 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfbbabd6a2b749d2bdeb36cdef5fe93e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "COLLECTING RESULTS | :   0%|          | 0/926 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRV exact-match rate : 0.8337\n",
      "Per-qubit rank acc   : q0=0.974, q1=0.968, q2=0.973, q3=0.974, q4=0.970, q5=0.974, q6=0.969, q7=0.976\n",
      "Entanglement-bin distribution (target | pred):\n",
      "     0 qubit entangled: 14.79% | 15.55%\n",
      "     2 qubit entangled: 15.66% | 17.17%\n",
      "     3 qubit entangled:  8.53% |  9.83%\n",
      "     4 qubit entangled: 10.91% | 13.93%\n",
      "     5 qubit entangled: 16.85% | 14.58%\n",
      "     6 qubit entangled: 13.61% | 12.20%\n",
      "     7 qubit entangled: 12.96% | 10.91%\n",
      "     8 qubit entangled:  6.70% |  5.83%\n"
     ]
    }
   ],
   "source": [
    "target_srvs = parse_srv_targets(ds.y[:samples])[valid_indices]\n",
    "predicted_srvs = torch.tensor(\n",
    "    get_srvs(simulator, backend_circuits, n_jobs=16),  \n",
    "    dtype=torch.long,\n",
    ")\n",
    "\n",
    "if target_srvs.shape != predicted_srvs.shape:\n",
    "    raise RuntimeError(f\"SRV shape mismatch: target {target_srvs.shape} vs predicted {predicted_srvs.shape}\")\n",
    "\n",
    "exact_match = (predicted_srvs == target_srvs).all(dim=1)\n",
    "per_qubit = (predicted_srvs == target_srvs).float().mean(dim=0)\n",
    "\n",
    "srv_exact_match_rate = exact_match.float().mean().item()\n",
    "print(f\"SRV exact-match rate : {srv_exact_match_rate:.4f}\")\n",
    "\n",
    "qubit_rank_acc = {i: acc for i, acc in enumerate(per_qubit.tolist())}\n",
    "print(\"Per-qubit rank acc   : \" + \", \".join(f\"q{i}={acc:.3f}\" for i, acc in qubit_rank_acc.items()))\n",
    "# print(\"Per-qubit rank acc   : \" + \", \".join(f\"q{i}={acc:.3f}\" for i, acc in enumerate(per_qubit.tolist())))\n",
    "\n",
    "pred_hist, ent_labels, pred_other = entanglement_histogram(predicted_srvs, num_qubits)\n",
    "targ_hist, _, targ_other = entanglement_histogram(target_srvs, num_qubits)\n",
    "\n",
    "if ent_labels:\n",
    "    print(\"Entanglement-bin distribution (target | pred):\")\n",
    "    for label, t_frac, p_frac in zip(ent_labels, targ_hist, pred_hist):\n",
    "        print(f\"  {label:>20}: {t_frac:6.2%} | {p_frac:6.2%}\")\n",
    "    if targ_other > 0 or pred_other > 0:\n",
    "        print(f\"  {'Other/invalid':>20}: {targ_other:6.2%} | {pred_other:6.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4cadab9b-8a4f-4af2-ad61-0e1c0b9e3a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6d2d3ac4c484ec89749a60f43338629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QUEUEING TASKS | :   0%|          | 0/599936 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "507930d4eb734dedb36f5ca0c7dd88bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PROCESSING TASKS | :   0%|          | 0/599936 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67ca0cf0553f461caa1304c2d44d734d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "COLLECTING RESULTS | :   0%|          | 0/599936 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "srvs = get_srvs(simulator, backend_circuits, n_jobs=47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ce9dd274-4424-4acf-ada6-12d7d5f6f810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AttributeError(\"Can't pickle local object 'decode_tensors_to_backend.<locals>._f'\")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_circuits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b37430-21f6-4e6b-bf6e-2fc483c58012",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
