{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "042b1a9a-72af-4a54-8949-ba7e33d7a77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import ast\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "import hydra\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Ensure local src/ is importable\n",
    "sys.path.insert(0, str(Path(os.getcwd()).parent / \"src\"))\n",
    "\n",
    "from my_genQC.inference.eval_metrics import UnitaryFrobeniusNorm, UnitaryInfidelityNorm\n",
    "from my_genQC.inference.evaluation_helper import get_unitaries, get_srvs\n",
    "from my_genQC.inference.sampling import generate_compilation_tensors, generate_tensors, decode_tensors_to_backend\n",
    "from my_genQC.pipeline.diffusion_pipeline import DiffusionPipeline\n",
    "from my_genQC.platform.simulation import Simulator, CircuitBackendType\n",
    "from my_genQC.platform.tokenizer.circuits_tokenizer import CircuitTokenizer\n",
    "from my_genQC.utils.misc_utils import infer_torch_device, get_entanglement_bins\n",
    "from my_genQC.dataset import circuits_dataset\n",
    "from my_genQC.models.config_model import ConfigModel\n",
    "from my_genQC.utils.config_loader import load_config, store_tensor, load_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16b90bb5-79b5-4697-bf32-6f4d6852179f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Cuda device has a capability of 8.6 (>= 8), allowing tf32 matmul.\n"
     ]
    }
   ],
   "source": [
    "# Config loading\n",
    "with hydra.initialize(version_base=None, config_path=\"../conf\"):\n",
    "    cfg = hydra.compose(config_name=\"config.yaml\", overrides=[\"evaluation=remote_model\"])\n",
    "    cfg = cfg[\"evaluation\"]\n",
    "\n",
    "device = torch.device(infer_torch_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d34c24e-fe4f-4073-8a2a-7216aeec22f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Loading tensor from `../datasets/paper_quditkit/srv_3q_dataset/dataset/ds_x.safetensors` onto device: cuda.\n",
      "[INFO]: Loading tensor from `../datasets/paper_quditkit/srv_3q_dataset/dataset/ds_y.safetensors` onto device: cuda.\n",
      "[INFO]: Instantiated config_dataset from given config on cuda.\n"
     ]
    }
   ],
   "source": [
    "def load_dataset(dataset_path: Path, device: torch.device):\n",
    "    config_path = os.path.join(dataset_path, \"config.yaml\")\n",
    "\n",
    "    if not os.path.exists(config_path):\n",
    "        raise FileNotFoundError(f\"Config file not found at {config_path}\")\n",
    "\n",
    "    cfg_data = load_config(config_path)\n",
    "    target = cfg_data.get(\"target\", \"\")\n",
    "    if target.endswith(\"MixedCircuitsConfigDataset\"):\n",
    "        dataset_cls = circuits_dataset.MixedCircuitsConfigDataset\n",
    "    else:\n",
    "        dataset_cls = circuits_dataset.CircuitsConfigDataset\n",
    "\n",
    "    dataset = dataset_cls.from_config_file(\n",
    "        config_path=config_path,\n",
    "        device=device,\n",
    "        save_path=os.path.join(dataset_path, \"dataset\", \"ds\")\n",
    "    )\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "ds = load_dataset(\"../datasets/paper_quditkit/srv_3q_dataset\", device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "879a94c4-0eaa-46be-9ec1-3d2ed51e5340",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pipeline(model_dir: Path | None, repo_id: str | None, device: torch.device):\n",
    "    if repo_id:\n",
    "        return DiffusionPipeline.from_pretrained(repo_id=repo_id, device=device)\n",
    "\n",
    "    if not model_dir:\n",
    "        raise ValueError(\"Provide either --model-dir or --hf-repo.\")\n",
    "\n",
    "    model_dir = model_dir.resolve()\n",
    "    config_path = model_dir if model_dir.is_dir() else model_dir.parent\n",
    "    cfg_file = config_path / \"config.yaml\"\n",
    "    if not cfg_file.exists():\n",
    "        raise FileNotFoundError(f\"Missing pipeline config at {cfg_file}\")\n",
    "\n",
    "    return DiffusionPipeline.from_config_file(config_path=str(config_path) + \"/\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50c60a85-17e5-4c93-b28a-700d48564eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "725acc8228434d908f35f9c1335438d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (incomplete total...): 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d80f7ba0fb940118f2d34fc4cd6015e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: `genQC.models.unet_qc.QC_Cond_UNet` instantiated from given `config` on cuda.\n",
      "[INFO]: Loading model from `/root/.cache/huggingface/hub/models--Floki00--qc_srv_3to8qubit/snapshots/18eece95eb50483c46dd4eef1cdac3e09afadd54/model.pt` onto device: cuda.\n",
      "[INFO]: `genQC.models.unet_qc.QC_Cond_UNet`. Freeze model: True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "902b973e0adb4f3ca7b96604b4a170e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "open_clip_model.safetensors:   0%|          | 0.00/605M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: `genQC.models.frozen_open_clip.CachedFrozenOpenCLIPEmbedder` instantiated from given `config` on cuda.\n",
      "[INFO]: `genQC.models.frozen_open_clip.CachedFrozenOpenCLIPEmbedder`. Found no key `save_type` in `config`. No state dict loaded.\n",
      "[INFO]: `genQC.models.frozen_open_clip.CachedFrozenOpenCLIPEmbedder`. Freeze model: True\n"
     ]
    }
   ],
   "source": [
    "pipeline = load_pipeline(\n",
    "    model_dir=Path(cfg.model_dir) if cfg.model_dir else None,\n",
    "    repo_id=cfg.hf_repo,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "pipeline.guidance_sample_mode = \"rescaled\"\n",
    "pipeline.scheduler.set_timesteps(cfg.model_params.sample_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd6e5a7a-6da9-45fc-b938-a2c128600491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CachedFrozenOpenCLIPEmbedder(\n",
       "  (model): CLIP(\n",
       "    (transformer): Transformer(\n",
       "      (resblocks): ModuleList(\n",
       "        (0-11): 12 x ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (token_embedding): Embedding(49408, 512)\n",
       "    (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.text_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8e960d4-0d5a-4947-b413-5e8635a00b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import open_clip\n",
    "from my_genQC.models.clip.frozen_open_clip import FrozenOpenCLIPEmbedderConfig, FrozenOpenCLIPEmbedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9429b0a4-247a-4111-a994-fd64cc85918a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Ignoring `pretrained='datacomp_xl_s13b_b90k'` because `model_name` has 'hf-hub' schema.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6d9913aac1548028bc68f4f1473c3ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "open_clip_config.json:   0%|          | 0.00/564 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8438788780c41b3afea8fb321e76ede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "open_clip_pytorch_model.bin:   0%|          | 0.00/1.71G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "FrozenOpenCLIPEmbedder(\n",
       "  (model): CLIP(\n",
       "    (transformer): Transformer(\n",
       "      (resblocks): ModuleList(\n",
       "        (0-11): 12 x ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (token_embedding): Embedding(49408, 768)\n",
       "    (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip_model = FrozenOpenCLIPEmbedder(\n",
    "    arch=\"hf-hub:lysandre/CLIP-ViT-L-14-laion2B-s32B-b82K\",\n",
    "    # version=\"\",\n",
    ")\n",
    "clip_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e797c14f-3b82-4368-a0a2-ba1713f15fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.text_encoder = clip_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbc2adf-00b5-41f2-8c2f-ed943359d5cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
