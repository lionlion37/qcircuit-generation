2025-09-20 14:41:15 - experiment.training_1758372072 - INFO - Starting experiment: training_1758372072
2025-09-20 14:41:15 - experiment.training_1758372072 - INFO - Configuration: {'model': {'type': 'QC_Compilation_UNet', 'params': {'model_features': [128, 128, 256], 'clr_dim': 8, 't_emb_size': 256, 'cond_emb_size': 512, 'num_heads': [8, 8, 2], 'num_res_blocks': [2, 2, 4], 'transformer_depths': [1, 2, 1], 'unitary_encoder_config': {'cond_emb_size': 512, 'model_features': [2, 32, 64, 512], 'num_heads': 8, 'transformer_depths': [2, 2], 'dropout': 0.2}}}, 'scheduler': {'type': 'DDIMScheduler', 'params': {'num_train_timesteps': 1000, 'beta_start': 0.0001, 'beta_end': 0.02, 'beta_schedule': 'cos_alpha', 'input_perturbation': 0.1, 'prediction_type': 'epsilon', 'eta': 1}}, 'training': {'learning_rate': 0.0001, 'optimizer': 'Adam', 'loss': 'MSELoss', 'num_epochs': 2, 'batch_size': 32, 'enable_guidance_train': True, 'guidance_train_p': 0.1, 'cached_text_enc': True}, 'text_encoder': {'type': 'CachedFrozenOpenCLIPEmbedder', 'params': {'arch': 'ViT-B-32', 'version': 'laion2b_s34b_b79k', 'max_length': 77, 'freeze': True, 'layer': 'penultimate', 'enable_cache_token_limit': True}}}
2025-09-20 14:41:15 - experiment.training_1758372072 - INFO - [setup] Initializing model architecture
2025-09-20 14:41:15 - experiment.training_1758372072 - INFO - [setup] Compiling model with optimizer and loss function
2025-09-20 14:41:15 - experiment.training_1758372072 - INFO - [training] Beginning training loop
2025-09-20 14:46:51 - experiment.training_1758372072 - INFO - [saving] Saving model to ./models/trained
2025-09-20 14:46:51 - experiment.training_1758372072 - INFO - Experiment 'training_1758372072' completed in 336.31 seconds
